{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142b90be",
   "metadata": {},
   "source": [
    "## Assignment 06  ðŸ§©\n",
    "\n",
    "**Aim:**  Implement Reinforcement Learning using an example of a maze environment that the\n",
    "agent needs to explore.\n",
    "\n",
    "**Student:** Kanaka Amin \n",
    "**Class:** BE | **Roll No:** 42501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ddc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff77e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [2, 1, 3, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cc418",
   "metadata": {},
   "source": [
    "**0** represents free spaces. <br>\n",
    "**1** represents walls or obstacles.<br>\n",
    "**2** is the start point.<br>\n",
    "**3** is the goal.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba3c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maze dimensions\n",
    "rows, cols = maze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862b4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and goal positions\n",
    "start = (3, 0)\n",
    "goal = (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "560f679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible actions (up, down, left, right)\n",
    "actions = [(-1, 0), (1, 0), (0, -1), (0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650a4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "alpha = 0.1    # Learning rate\n",
    "gamma = 0.9    # Discount factor\n",
    "epsilon = 0.1  # Exploration rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856049f7",
   "metadata": {},
   "source": [
    "* Learning rate: Determines how much the model adjusts its parameters based on the error during training.\n",
    "\n",
    "* Discount factor: In reinforcement learning, it determines the importance of future rewards relative to immediate ones.\n",
    "\n",
    "* Exploration rate: Controls the balance between exploring new actions and exploiting known good ones in reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2848128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-table (Initialize Q-values for each state-action pair)\n",
    "Q = np.zeros((rows, cols, len(actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5725502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a position is valid\n",
    "def is_valid(pos):\n",
    "    return 0 <= pos[0] < rows and 0 <= pos[1] < cols and maze[pos] != 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e47200ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(len(actions))  # Explore\n",
    "    else:\n",
    "        return np.argmax(Q[state[0], state[1], :])  # Exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0fddf",
   "metadata": {},
   "source": [
    "## Q-learning : \n",
    "* Used in reinforcement learning\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4bc590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q(state, action, reward, next_state):\n",
    "    old_q = Q[state[0], state[1], action]\n",
    "    next_max_q = np.max(Q[next_state[0], next_state[1], :])\n",
    "    Q[state[0], state[1], action] = old_q + alpha * (reward + gamma * next_max_q - old_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c1450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the agent\n",
    "def train_agent(episodes=1000):\n",
    "    for _ in range(episodes):\n",
    "        state = start\n",
    "        while state != goal:\n",
    "            action = choose_action(state)\n",
    "            next_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "\n",
    "            if not is_valid(next_state):\n",
    "                next_state = state  # If the action leads to an invalid state, stay in the same place\n",
    "                reward = -1  # Penalty for hitting a wall\n",
    "            elif next_state == goal:\n",
    "                reward = 10  # Reward for reaching the goal\n",
    "            else:\n",
    "                reward = -0.1  # Small negative reward for each step taken\n",
    "\n",
    "            update_q(state, action, reward, next_state)\n",
    "            state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48cebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a25e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_maze():\n",
    "    path = np.zeros((rows, cols))\n",
    "    state = start\n",
    "    path[state] = 2  # Mark start\n",
    "    while state != goal:\n",
    "        action = np.argmax(Q[state[0], state[1], :])\n",
    "        next_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "        if not is_valid(next_state) or state == next_state:\n",
    "            break  # Stop if stuck\n",
    "        state = next_state\n",
    "        path[state] = 3  # Mark path\n",
    "    path[goal] = 4  # Mark goal\n",
    "    \n",
    "    plt.imshow(path, cmap='pink', interpolation='nearest')\n",
    "    plt.title('Agent Path through the Maze')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the maze with the agent's path\n",
    "plot_maze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712fcb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path taken by the agent (from start to goal):\n",
      "(3, 0) -> (2, 0) -> (2, 1) -> (2, 2) -> (3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the learned path\n",
    "def visualize_path():\n",
    "    state = start\n",
    "    path = [state]  # Initialize path with the start state\n",
    "    while state != goal:\n",
    "        action = np.argmax(Q[state[0], state[1], :])\n",
    "        next_state = (state[0] + actions[action][0], state[1] + actions[action][1])\n",
    "        if not is_valid(next_state) or state == next_state:\n",
    "            break  # Stop if stuck\n",
    "        state = next_state\n",
    "        path.append(state)  # Append the next state to the path\n",
    "    if state == goal:\n",
    "        print(\"Path taken by the agent (from start to goal):\")\n",
    "        print(\" -> \".join(str(step) for step in path))\n",
    "    else:\n",
    "        print(\"The agent could not find a path to the goal.\")\n",
    "\n",
    "# Visualize the path\n",
    "visualize_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e6a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Maze:\n",
    "    def __init__(self, maze):\n",
    "        self.maze = maze\n",
    "        self.start_position = self.find_position(2)  # Position of '2' (start)\n",
    "        self.goal_position = self.find_position(3)   # Position of '3' (goal)\n",
    "        self.agent_position = self.start_position    # Initialize the agent at the start position\n",
    "\n",
    "    def find_position(self, value):\n",
    "        # Find the (row, col) position of the given value (start or goal)\n",
    "        result = np.where(self.maze == value)\n",
    "        return (result[0][0], result[1][0])\n",
    "    \n",
    "    def set_agent_position(self, pos):\n",
    "        self.agent_position = pos\n",
    "\n",
    "    def render(self):\n",
    "        # Create a copy of the maze to visualize\n",
    "        visual_maze = self.maze.copy()\n",
    "        \n",
    "        # Highlight the agent's position (using a distinct marker)\n",
    "        agent_x, agent_y = self.agent_position\n",
    "        visual_maze[agent_x, agent_y] = 9  # Mark the agent's position with '9'\n",
    "        \n",
    "        # Create a color map for visualization\n",
    "        color_map = {\n",
    "            0: 'white',  # Free space\n",
    "            1: 'black',  # Wall\n",
    "            2: 'blue',   # Start position\n",
    "            3: 'red',    # Goal position\n",
    "            9: 'green'   # Agent's current position\n",
    "        }\n",
    "\n",
    "        # Prepare the grid for visualization\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        for i in range(visual_maze.shape[0]):\n",
    "            for j in range(visual_maze.shape[1]):\n",
    "                color = color_map[visual_maze[i, j]]\n",
    "                ax.add_patch(plt.Rectangle((j, i), 1, 1, color=color))\n",
    "        \n",
    "        # Set grid and title\n",
    "        plt.xlim(0, visual_maze.shape[1])\n",
    "        plt.ylim(0, visual_maze.shape[0])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xticks([])  # Hide x-axis ticks\n",
    "        plt.yticks([])  # Hide y-axis ticks\n",
    "        plt.title('Maze Visualization')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "maze_data = np.array([\n",
    "    [0, 0, 0, 1],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [2, 1, 3, 0]\n",
    "])\n",
    "\n",
    "maze = Maze(maze_data)\n",
    "maze.render()  # Render the initial state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914eb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
